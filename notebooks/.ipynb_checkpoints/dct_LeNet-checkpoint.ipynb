{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0991f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.fft import dct\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3194f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\TU_KL\\thesis\\cnn_comp\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Resize((32, 32)),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c31b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCT_layer(nn.Module):\n",
    "    def __init__(self,out_features: int):\n",
    "        super(DCT_layer, self).__init__()\n",
    "        \n",
    "        self.out_features = out_features\n",
    "        \n",
    "        default_dtype = torch.get_default_dtype()\n",
    "        self.fc = nn.Parameter(torch.arange((self.out_features), dtype=default_dtype).reshape(-1,1))     \n",
    "        \n",
    "        self.fc.register_hook(lambda grad: grad / (torch.linalg.norm(grad) + 1e-8))\n",
    "\n",
    "    def dct_kernel(self,t): \n",
    "        dct_m = np.sqrt(2/(self.out_features)) * torch.cos(0.5 * np.pi * self.fc * (2 * t + 1) / self.out_features)\n",
    "        \n",
    "        dct_m[0] = dct_m[0]/np.sqrt(2)\n",
    "        \n",
    "        return dct_m\n",
    "    \n",
    "        \n",
    "    def forward(self,x):\n",
    "#         print(x.shape)\n",
    "        t = torch.arange(x.shape[-1]).reshape(1,-1)\n",
    "        w = self.dct_kernel(t) \n",
    "        \n",
    "        \n",
    "        y = F.linear(x,w)   \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3177a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCT_conv_layer(nn.Module):\n",
    "    def __init__(self,in_channels: int,out_channels: int, kernel_size, stride=1,padding=0):\n",
    "        super(DCT_conv_layer, self).__init__()\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        default_dtype = torch.get_default_dtype()\n",
    "        self.fc = nn.Parameter(torch.arange((self.kernel_size), dtype=default_dtype).reshape(-1,1))     \n",
    "        \n",
    "        self.fc.register_hook(lambda grad: grad / (torch.linalg.norm(grad) + 1e-8))\n",
    "\n",
    "    def dct_kernel(self,t): \n",
    "        dct_m = np.sqrt(2/(self.kernel_size)) * torch.cos(0.5 * np.pi * self.fc * (2 * t + 1) / self.kernel_size)\n",
    "        \n",
    "        dct_m[0] = dct_m[0]/np.sqrt(2)\n",
    "        \n",
    "        return dct_m\n",
    "    \n",
    "    def kernel_reshape(self,w):\n",
    "        dct_l1 = []\n",
    "        for i in range(self.out_channels):\n",
    "            dct_l1.append(w)\n",
    "            \n",
    "        a = torch.stack(dct_l1,0)\n",
    "        \n",
    "        dct_l2 = []\n",
    "        for i in range(self.in_channels):\n",
    "            dct_l2.append(a)\n",
    "        \n",
    "        b = torch.stack(dct_l2,1)\n",
    "        \n",
    "        return b\n",
    "        \n",
    "    def forward(self,x):\n",
    "#         print(x.shape)\n",
    "#         default_dtype = torch.get_default_dtype()\n",
    "#         self.fc = nn.Parameter(torch.arange((x.shape[-1]), dtype=default_dtype, device=device).reshape(-1,1))\n",
    "#         self.fc.register_hook(lambda grad: grad / (torch.linalg.norm(grad) + 1e-8))\n",
    "        \n",
    "        \n",
    "        t = torch.arange(self.kernel_size).reshape(1,-1)\n",
    "        w = self.dct_kernel(t) \n",
    "        \n",
    "#         conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size = self.kernel_size, \n",
    "#                          stride= self.stride, padding = self.padding).to(device)\n",
    "        w = self.kernel_reshape(w)\n",
    "#         print(x.shape)\n",
    "#         print(w.shape)\n",
    "#         print((x@w.T).shape)\n",
    "        \n",
    "        y = F.conv2d(x,w,stride = self.stride, padding = self.padding)   \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbdf1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCT_LeNet(\n",
      "  (conv1): DCT_conv_layer()\n",
      "  (conv2): DCT_conv_layer()\n",
      "  (conv3): DCT_conv_layer()\n",
      "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DCT_LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DCT_LeNet, self).__init__()\n",
    "        self.conv1 = DCT_conv_layer(1, 6, 5)\n",
    "        self.conv2 = DCT_conv_layer(6, 16, 5)\n",
    "        self.conv3 = DCT_conv_layer(16, 120, 5)  \n",
    "        \n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "#         self.dct = DCT_layer(84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "#         x = F.relu(self.dct(x))\n",
    "#         x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "dct_net = DCT_LeNet()\n",
    "print(dct_net)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7444ad14",
   "metadata": {},
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5)  \n",
    "        \n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "lenet = LeNet()\n",
    "print(lenet)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1722cf63",
   "metadata": {},
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "batch_size = 32\n",
    "in_features = 4096\n",
    "out_features = 4096\n",
    "\n",
    "x = torch.nn.Parameter(torch.randn(batch_size, in_features))\n",
    "dct_layer = DCT_layer(out_features)\n",
    "\n",
    "linear_layer = nn.Linear(in_features,out_features)\n",
    "y = dct_layer(x)\n",
    "\n",
    "make_dot(\n",
    "    y,\n",
    "    params=dict(dct_layer.named_parameters()),\n",
    "    show_saved=True\n",
    ").render('../LinearDCT-dev_alexnet2', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58e0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,model,criterion,optimizer):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for X, y in dataloader:\n",
    "        inputs, labels = X, y\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "    \n",
    "    print(f'Training Loss: {train_loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50561ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X, y\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "161b6df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCT_LeNet\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\TU_KL\\thesis\\cnn_comp\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 11.61443829\n",
      "Test Error: \n",
      " Accuracy: 13.8%, Avg loss: 2.308293 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Training Loss: 9.72850603\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 2.387463 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Training Loss: 9.40229609\n",
      "Test Error: \n",
      " Accuracy: 12.4%, Avg loss: 2.311744 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Training Loss: 9.27891084\n",
      "Test Error: \n",
      " Accuracy: 12.4%, Avg loss: 2.300166 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Training Loss: 9.16852391\n",
      "Test Error: \n",
      " Accuracy: 13.7%, Avg loss: 2.291467 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(dct_net.parameters(), lr=1e-6, momentum=0.9)\n",
    "\n",
    "print(\"DCT_LeNet\")\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(trainloader, dct_net, criterion, optimizer)\n",
    "    test(testloader, dct_net, criterion)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7c3cebb",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lenet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"LeNet\")\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(trainloader, lenet, criterion, optimizer)\n",
    "    test(testloader, lenet, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb90c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
